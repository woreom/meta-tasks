{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woreom/miniconda3/envs/few/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import models\n",
    "from models.modules import get_child_dict\n",
    "from torchsummary import summary\n",
    "import utils\n",
    "import utils.optimizers as optimizers\n",
    "from models.encoders.autoencoders import DecoderResidualBlock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet12Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet12Decoder, self).__init__()\n",
    "        configs = [1, 2, 2, 2]\n",
    "        # self.linear = nn.Linear(in_features=512, out_features=512*3*3)\n",
    "        self.conv1 = DecoderResidualBlock(hidden_channels=512, output_channels=256, layers=configs[0])\n",
    "        self.conv2 = DecoderResidualBlock(hidden_channels=256, output_channels=128, layers=configs[1])\n",
    "        self.conv3 = DecoderResidualBlock(hidden_channels=128, output_channels=64,  layers=configs[2])\n",
    "        self.conv4 = DecoderResidualBlock(hidden_channels=64,  output_channels=64,  layers=configs[3])\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=3, stride=2, padding=7,\n",
    "                               output_padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "        self.gate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x = x.reshape((x.shape[0], 512, 1, 1))\n",
    "        print(x.shape)\n",
    "        # x = self.linear(x)\n",
    "        # x = x.reshape((x.shape[0],-1,3,3))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.gate(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder input: torch.Size([1, 512, 3, 3])\n",
      "torch.Size([1, 512, 3, 3])\n",
      "encoder output: torch.Size([1, 3, 84, 84])\n",
      "torch.Size([2, 512, 3, 3])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-2            [-1, 512, 3, 3]               0\n",
      "            Conv2d-3            [-1, 512, 3, 3]       2,359,296\n",
      "       BatchNorm2d-4            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-5            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-6            [-1, 256, 6, 6]       1,179,648\n",
      "       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n",
      "              ReLU-8            [-1, 512, 3, 3]               0\n",
      "   ConvTranspose2d-9            [-1, 256, 6, 6]         131,072\n",
      "DecoderResidualLayer-10            [-1, 256, 6, 6]               0\n",
      "DecoderResidualBlock-11            [-1, 256, 6, 6]               0\n",
      "      BatchNorm2d-12            [-1, 256, 6, 6]             512\n",
      "             ReLU-13            [-1, 256, 6, 6]               0\n",
      "           Conv2d-14            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-15            [-1, 256, 6, 6]             512\n",
      "             ReLU-16            [-1, 256, 6, 6]               0\n",
      "           Conv2d-17            [-1, 256, 6, 6]         589,824\n",
      "DecoderResidualLayer-18            [-1, 256, 6, 6]               0\n",
      "      BatchNorm2d-19            [-1, 256, 6, 6]             512\n",
      "             ReLU-20            [-1, 256, 6, 6]               0\n",
      "           Conv2d-21            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-22            [-1, 256, 6, 6]             512\n",
      "             ReLU-23            [-1, 256, 6, 6]               0\n",
      "  ConvTranspose2d-24          [-1, 128, 12, 12]         294,912\n",
      "      BatchNorm2d-25            [-1, 256, 6, 6]             512\n",
      "             ReLU-26            [-1, 256, 6, 6]               0\n",
      "  ConvTranspose2d-27          [-1, 128, 12, 12]          32,768\n",
      "DecoderResidualLayer-28          [-1, 128, 12, 12]               0\n",
      "DecoderResidualBlock-29          [-1, 128, 12, 12]               0\n",
      "      BatchNorm2d-30          [-1, 128, 12, 12]             256\n",
      "             ReLU-31          [-1, 128, 12, 12]               0\n",
      "           Conv2d-32          [-1, 128, 12, 12]         147,456\n",
      "      BatchNorm2d-33          [-1, 128, 12, 12]             256\n",
      "             ReLU-34          [-1, 128, 12, 12]               0\n",
      "           Conv2d-35          [-1, 128, 12, 12]         147,456\n",
      "DecoderResidualLayer-36          [-1, 128, 12, 12]               0\n",
      "      BatchNorm2d-37          [-1, 128, 12, 12]             256\n",
      "             ReLU-38          [-1, 128, 12, 12]               0\n",
      "           Conv2d-39          [-1, 128, 12, 12]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 12, 12]             256\n",
      "             ReLU-41          [-1, 128, 12, 12]               0\n",
      "  ConvTranspose2d-42           [-1, 64, 24, 24]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 12, 12]             256\n",
      "             ReLU-44          [-1, 128, 12, 12]               0\n",
      "  ConvTranspose2d-45           [-1, 64, 24, 24]           8,192\n",
      "DecoderResidualLayer-46           [-1, 64, 24, 24]               0\n",
      "DecoderResidualBlock-47           [-1, 64, 24, 24]               0\n",
      "      BatchNorm2d-48           [-1, 64, 24, 24]             128\n",
      "             ReLU-49           [-1, 64, 24, 24]               0\n",
      "           Conv2d-50           [-1, 64, 24, 24]          36,864\n",
      "      BatchNorm2d-51           [-1, 64, 24, 24]             128\n",
      "             ReLU-52           [-1, 64, 24, 24]               0\n",
      "           Conv2d-53           [-1, 64, 24, 24]          36,864\n",
      "DecoderResidualLayer-54           [-1, 64, 24, 24]               0\n",
      "      BatchNorm2d-55           [-1, 64, 24, 24]             128\n",
      "             ReLU-56           [-1, 64, 24, 24]               0\n",
      "           Conv2d-57           [-1, 64, 24, 24]          36,864\n",
      "      BatchNorm2d-58           [-1, 64, 24, 24]             128\n",
      "             ReLU-59           [-1, 64, 24, 24]               0\n",
      "  ConvTranspose2d-60           [-1, 64, 48, 48]          36,864\n",
      "      BatchNorm2d-61           [-1, 64, 24, 24]             128\n",
      "             ReLU-62           [-1, 64, 24, 24]               0\n",
      "  ConvTranspose2d-63           [-1, 64, 48, 48]           4,096\n",
      "DecoderResidualLayer-64           [-1, 64, 48, 48]               0\n",
      "DecoderResidualBlock-65           [-1, 64, 48, 48]               0\n",
      "      BatchNorm2d-66           [-1, 64, 48, 48]             128\n",
      "             ReLU-67           [-1, 64, 48, 48]               0\n",
      "  ConvTranspose2d-68            [-1, 3, 84, 84]           1,728\n",
      "          Sigmoid-69            [-1, 3, 84, 84]               0\n",
      "================================================================\n",
      "Total params: 6,452,416\n",
      "Trainable params: 6,452,416\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 16.18\n",
      "Params size (MB): 24.61\n",
      "Estimated Total Size (MB): 40.81\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=ResNet12Decoder()\n",
    "_input = torch.randn((1, 512, 3, 3))\n",
    "\n",
    "print(f\"decoder input: {_input.shape}\")\n",
    "\n",
    "output = model(_input)\n",
    "\n",
    "print(f\"encoder output: {output.shape}\")\n",
    "\n",
    "model=model.cuda()\n",
    "print(summary(model,(512, 3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input: torch.Size([25, 3, 84, 84])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = models.make('convnet4', {'bn_args': {'track_running_stats': False, 'n_episode': 4}},\n",
    "                        'logistic', {'n_way': 5, 'in_dim': 800})\n",
    "\n",
    "optimizer, lr_scheduler = optimizers.make(\n",
    "      'adam', model.parameters(), lr= 0.001)\n",
    "\n",
    "inner_args = {'n_step': 5, 'encoder_lr': 0.01, 'classifier_lr': 0.01, 'first_order': False, 'frozen': ['bn'], 'reset_classifier': False, 'momentum': 0.0, 'weight_decay': 0.0}\n",
    "\n",
    "\n",
    "model.eval()\n",
    "model.reset_classifier()\n",
    "# a dictionary of parameters that will be updated in the inner loop\n",
    "params = OrderedDict(model.named_parameters())\n",
    "\n",
    "for name in list(params.keys()):\n",
    "    if not params[name].requires_grad:\n",
    "        params.pop(name)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "_input = torch.randn((25,3,84,84)).to(device)\n",
    "\n",
    "print(f\"encoder input: {_input.shape}\")\n",
    "\n",
    "output = model.encoder(_input, get_child_dict(params, 'encoder'))\n",
    "\n",
    "print(f\"encoder output: {output.shape}\")\n",
    "\n",
    "output = model.classifier(output, get_child_dict(params, 'classifier'))\n",
    "\n",
    "print(f\"classifier output: {output.shape}\")\n",
    "\n",
    "print(summary(model.encoder,(3,84,84)))\n",
    "print(summary(model.classifier,(1, 1600)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.9K\n",
      "encoder input: torch.Size([4, 5, 3, 84, 84])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m _input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m84\u001b[39m,\u001b[38;5;241m84\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_input\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary(model,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m84\u001b[39m,\u001b[38;5;241m84\u001b[39m)))\n",
      "File \u001b[0;32m~/miniconda3/envs/few/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/M3/Projects/Rowan/PyTorch-MAML/models/maml.py:212\u001b[0m, in \u001b[0;36mMAML.forward\u001b[0;34m(self, x_shot, x_query, y_shot, inner_args, meta_train)\u001b[0m\n\u001b[1;32m    209\u001b[0m params \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_parameters())\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(params\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params[name]\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28many\u001b[39m(s \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43minner_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrozen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m    213\u001b[0m     params\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[1;32m    215\u001b[0m logits \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "model = models.make('convnet4', {'bn_args': {'track_running_stats': False, 'n_episode': 4}},\n",
    "                        'logistic', {'n_way': 5, 'in_dim': 800})\n",
    "optimizer, lr_scheduler = optimizers.make(\n",
    "      'adam', model.parameters(), lr= 0.001)\n",
    "\n",
    "inner_args = {'n_step': 5, 'encoder_lr': 0.01, 'classifier_lr': 0.01, 'first_order': False, 'frozen': ['bn'], 'reset_classifier': False, 'momentum': 0.0, 'weight_decay': 0.0}\n",
    "\n",
    "print(utils.compute_n_params(model))\n",
    "model.eval()\n",
    "\n",
    "model.reset_classifier()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "_input = torch.randn((4,5,3,84,84)).to(device)\n",
    "\n",
    "print(f\"encoder input: {_input.shape}\")\n",
    "\n",
    "output = model(x_shot=_input, x_query=_input, y_shot=_input, inner_args=[], meta_train=False)\n",
    "\n",
    "print(f\"encoder output: {output.shape}\")\n",
    "\n",
    "\n",
    "print(summary(model,(3,84,84)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shallow_Decoder(torch.nn.Sequential):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden=64,\n",
    "                 channels=1,\n",
    "                 max_pool=False,\n",
    "                 layers=4,\n",
    "                 max_pool_factor=1.0):\n",
    "        core = [nn.ConvTranspose2d(in_channels=channels, out_channels=hidden, kernel_size=3,\n",
    "                                   stride=2, padding=1,), nn.BatchNorm2d(hidden), nn.ReLU()]\n",
    "        for _ in range(layers - 2):\n",
    "            core.extend([nn.ConvTranspose2d(in_channels=hidden, out_channels=hidden, kernel_size=3,\n",
    "                                            stride=1, padding=0,), nn.BatchNorm2d(hidden), nn.ReLU()])\n",
    "            \n",
    "        core.extend([nn.ConvTranspose2d(in_channels=hidden, out_channels=3, kernel_size=2,\n",
    "                                        stride=1, padding=0,), nn.BatchNorm2d(3),nn.Sigmoid()])\n",
    "            \n",
    "        super(Shallow_Decoder, self).__init__(*core)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.reshape((x.shape[0], 1, 40, 40))\n",
    "        x = super(Shallow_Decoder, self).forward(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder input: torch.Size([1, 1600])\n",
      "encoder output: torch.Size([1, 3, 84, 84])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [-1, 64, 79, 79]             640\n",
      "       BatchNorm2d-2           [-1, 64, 79, 79]             128\n",
      "              ReLU-3           [-1, 64, 79, 79]               0\n",
      "   ConvTranspose2d-4           [-1, 64, 81, 81]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 81, 81]             128\n",
      "              ReLU-6           [-1, 64, 81, 81]               0\n",
      "   ConvTranspose2d-7           [-1, 64, 83, 83]          36,928\n",
      "       BatchNorm2d-8           [-1, 64, 83, 83]             128\n",
      "              ReLU-9           [-1, 64, 83, 83]               0\n",
      "  ConvTranspose2d-10            [-1, 3, 84, 84]             771\n",
      "      BatchNorm2d-11            [-1, 3, 84, 84]               6\n",
      "          Sigmoid-12            [-1, 3, 84, 84]               0\n",
      "================================================================\n",
      "Total params: 75,657\n",
      "Trainable params: 75,657\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 29.33\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 29.62\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Shallow_Decoder()\n",
    "_input = torch.randn((1, 1600))\n",
    "\n",
    "print(f\"decoder input: {_input.shape}\")\n",
    "\n",
    "output = model(_input)\n",
    "\n",
    "print(f\"encoder output: {output.shape}\")\n",
    "\n",
    "model=model.cuda()\n",
    "print(summary(model,(1600, 1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Decoder(torch.nn.Sequential):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden=64,\n",
    "                 channels=64,\n",
    "                 max_pool=False,\n",
    "                 layers=4,\n",
    "                 max_pool_factor=1.0):\n",
    "        core = [nn.ConvTranspose2d(in_channels=channels, out_channels=hidden, kernel_size=3,\n",
    "                                   stride=2, padding=0,), nn.BatchNorm2d(hidden), nn.ReLU()]\n",
    "        for _ in range(layers - 2):\n",
    "            core.extend([nn.ConvTranspose2d(in_channels=hidden, out_channels=hidden, kernel_size=5,\n",
    "                                            stride=2, padding=2,), nn.BatchNorm2d(hidden), nn.ReLU()])\n",
    "            \n",
    "        core.extend([nn.ConvTranspose2d(in_channels=hidden, out_channels=3, kernel_size=6,\n",
    "                                        stride=2, padding=1,), nn.BatchNorm2d(3),nn.Sigmoid()])\n",
    "            \n",
    "        super(Deep_Decoder, self).__init__(*core)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.reshape((x.shape[0], 64, 5, 5))\n",
    "        # print(x.shape)\n",
    "        # x = x.expand(x.shape[0], 1600, 3, 3)\n",
    "        x = super(Deep_Decoder, self).forward(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder input: torch.Size([1, 1600])\n",
      "encoder output: torch.Size([1, 3, 84, 84])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [-1, 64, 11, 11]          36,928\n",
      "       BatchNorm2d-2           [-1, 64, 11, 11]             128\n",
      "              ReLU-3           [-1, 64, 11, 11]               0\n",
      "   ConvTranspose2d-4           [-1, 64, 21, 21]         102,464\n",
      "       BatchNorm2d-5           [-1, 64, 21, 21]             128\n",
      "              ReLU-6           [-1, 64, 21, 21]               0\n",
      "   ConvTranspose2d-7           [-1, 64, 41, 41]         102,464\n",
      "       BatchNorm2d-8           [-1, 64, 41, 41]             128\n",
      "              ReLU-9           [-1, 64, 41, 41]               0\n",
      "  ConvTranspose2d-10            [-1, 3, 84, 84]           6,915\n",
      "      BatchNorm2d-11            [-1, 3, 84, 84]               6\n",
      "          Sigmoid-12            [-1, 3, 84, 84]               0\n",
      "================================================================\n",
      "Total params: 249,161\n",
      "Trainable params: 249,161\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.77\n",
      "Params size (MB): 0.95\n",
      "Estimated Total Size (MB): 4.73\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Deep_Decoder()\n",
    "_input = torch.randn((1, 1600))\n",
    "\n",
    "print(f\"decoder input: {_input.shape}\")\n",
    "\n",
    "output = model(_input)\n",
    "\n",
    "print(f\"encoder output: {output.shape}\")\n",
    "\n",
    "model=model.cuda()\n",
    "print(summary(model,(1600, 1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "few",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
